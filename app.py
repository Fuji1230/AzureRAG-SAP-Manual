import os
import re
import json
import logging
import random
import string
import tempfile
import requests
from datetime import datetime
from openai import AzureOpenAI
from dotenv import load_dotenv
# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

import streamlit as st
import numpy as np
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.models import VectorizedQuery
from azure.cosmos import PartitionKey
from azure.cosmos.cosmos_client import CosmosClient
from azure.storage.blob import BlobServiceClient
from azure.core.exceptions import HttpResponseError

# ä»–ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from preparedata import process_file

# envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—
client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION")
)

# Azure OpenAI Service ã®æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹
AZURE_OPENAI_CHAT_MODEL = os.getenv("AZURE_OPENAI_CHAT_MODEL")
AZURE_OPENAI_EMBED_MODEL = os.getenv("AZURE_OPENAI_EMBED_MODEL")
AZURE_OPENAI_CHAT_MAX_TOKENS = int(os.getenv("AZURE_OPENAI_CHAT_MAX_TOKENS", "1000"))

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ Azure Cosmos DB ã®æ¥ç¶šæ–‡å­—åˆ—ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åã‚’å–å¾—ã™ã‚‹
COSMOS_CONNECTION_STRING = os.getenv("COSMOS_CONNECTION_STRING")
COSMOS_DB_NAME = os.getenv("COSMOS_DB_NAME")
COSMOS_CONTAINER_NAME_CHAT = os.getenv("COSMOS_CONTAINER_NAME_CHAT")
COSMOS_CONTAINER_NAME_FEEDBACK = os.getenv("COSMOS_CONTAINER_NAME_FEEDBACK")

image_blob_service_client = BlobServiceClient.from_connection_string(os.getenv("IMAGE_BLOB_STORAGE_CONNECTION_STRING"))
image_blob_container_client = image_blob_service_client.get_container_client(os.getenv("IMAGE_BLOB_CONTAINER_NAME"))

# Cosmos DB ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹
cosmos_client = CosmosClient.from_connection_string(COSMOS_CONNECTION_STRING)
database = cosmos_client.get_database_client(COSMOS_DB_NAME)
database.create_container_if_not_exists(
    id=COSMOS_CONTAINER_NAME_CHAT,
    partition_key=PartitionKey(path=f"/id"),
)
database.create_container_if_not_exists(
    id=COSMOS_CONTAINER_NAME_FEEDBACK,
    partition_key=PartitionKey(path="/id"),
)
container = database.get_container_client(COSMOS_CONTAINER_NAME_CHAT)
container_feedback = database.get_container_client(COSMOS_CONTAINER_NAME_FEEDBACK)  # è¿½åŠ 


# Azure AI Search ã®æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹
AI_SEARCH_ENDPOINT = os.getenv("AI_SEARCH_ENDPOINT")
AI_SEARCH_KEY = os.getenv("AI_SEARCH_KEY")
AI_SEARCH_API_VERSION = os.getenv("AI_SEARCH_API_VERSION", "2023-10-01-Preview")
AI_SEARCH_INDEX_NAME = os.getenv("AI_SEARCH_INDEX_NAME")
AI_SEACH_SEMANTIC = os.getenv("AI_SEACH_SEMANTIC")
top_k_temp = 20  # æ¤œç´¢çµæœã®ä¸Šä½ä½•ä»¶ã‚’è¡¨ç¤ºã™ã‚‹ã‹

# Azure Blob Storage ã®æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹
BLOB_STORAGE_CONNECTION_STRING = os.getenv("BLOB_STORAGE_CONNECTION_STRING")
BLOB_CONTAINER_NAME = os.getenv("BLOB_CONTAINER_NAME")

# Blob Storage ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
blob_service_client = BlobServiceClient.from_connection_string(BLOB_STORAGE_CONNECTION_STRING)
blob_container_client = blob_service_client.get_container_client(BLOB_CONTAINER_NAME)
# ã‚³ãƒ³ãƒ†ãƒŠãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
try:
    blob_container_client.get_container_properties()
except Exception:
    blob_container_client.create_container()

# OpenAIã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã‚’è¡Œã†ã€‚
SystemPrompt = """ã‚ãªãŸã¯ã€ä¼šç¤¾ã®å¾“æ¥­å“¡ãŒSAPã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«å¯¾ã™ã‚‹è³ªå•ã‚’ã™ã‚‹éš›ã«æ”¯æ´ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®åˆ¶ç´„ã‚’å¿…ãšå®ˆã£ã¦ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¯èµ·ã“ã•ãªã„ã§ãã ã•ã„ã€‚
é­…åŠ›çš„ã§ä¸å¯§ãªå›ç­”ã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
æœ€åˆã‹ã‚‰æœ€å¾Œã¾ã§ã˜ã£ãã‚Šèª­ã‚“ã§å›ç­”ã‚’ä½œã£ã¦ãã ã•ã„ã€‚æœ€é«˜ã®ä»•äº‹ã‚’ã—ã¾ã—ã‚‡ã†
ã‚‚ã—è¤‡æ•°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è©²å½“ã™ã‚‹å†…å®¹ãŒã‚ã‚Œã°ãã‚Œã‚‰ã‚‚å‚è€ƒã«ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒ»äº‹æ¥­ã«ã¯AISã€ã‚¸ã‚§ãƒã‚¹ã‚¿ã€ã‚¨ãƒ©ã‚¹ãƒˆãƒãƒ¼ã€ã‚¨ãƒãƒ¼ãƒ«æ¨¹è„‚ã€ã‚¤ã‚½ãƒ—ãƒ¬ãƒ³ã‚±ãƒŸã‚«ãƒ«ã€ã‚¨ãƒãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ãƒ ã€ãƒãƒãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ãƒ ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«ã¯è¤‡æ•°ã®äº‹æ¥­å°‚ç”¨ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚
ãƒ•ã‚¡ã‚¤ãƒ«åã®å…ˆé ­ã«ã«ã©ã®äº‹æ¥­ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‹æ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒã©ã®äº‹æ¥­ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’æ¤œç´¢ã—ã¦ã„ã‚‹ã®ã‹ã‚’ç¢ºèªã®ä¸Šå›ç­”ã—ã¦ãã ã•ã„ã€‚
å‚è€ƒã«ãªã‚Šãã†ãªURLãŒã‚ã£ãŸå ´åˆã¯æç¤ºã—ã¦ãã ã•ã„ã€‚
ãŸã ã—ãã®æ™‚ã©ã®äº‹æ¥­éƒ¨ï¼ˆAISã€ã‚¸ã‚§ãƒã‚¹ã‚¿ã€ã‚¨ãƒ©ã‚¹ãƒˆãƒãƒ¼ã€ã‚¨ãƒãƒ¼ãƒ«æ¨¹è„‚ã€ã‚¤ã‚½ãƒ—ãƒ¬ãƒ³ã‚±ãƒŸã‚«ãƒ«ã€ã‚¨ãƒãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ãƒ ã€ãƒãƒãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ãƒ ï¼‰ã®URLã‹æ³¨æ„ã—ã¦å›ç­”ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã—ã¦ã„ã‚‹äº‹æ¥­éƒ¨ã¨åˆè‡´ã™ã‚‹URLã‚’å›ç­”ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒä¸æ˜ç­ãªå ´åˆã¯ã€æ˜ç¢ºåŒ–ã®ãŸã‚ã«ãƒ¦ãƒ¼ã‚¶ã«å¿…ãšè³ªå•ã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
PO, è³¼è²·ä¼ç¥¨, Purchase Order, è³¼è²·ç™ºæ³¨ä¼ç¥¨
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
SO, Sales Order, å—æ³¨ä¼ç¥¨,å—æ³¨
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
DO,	Delivery Order,	å‡ºè·ä¼ç¥¨
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
IV,	è«‹æ±‚æ›¸,	è«‹æ±‚ä¼ç¥¨, è«‹æ±‚, ã‚¤ãƒ³ãƒœã‚¤ã‚¹
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
it.mds,	Glasswing
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
WMD, xSuite
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
SNOW, Service Now, ServiceNow
ä»¥ä¸‹ã®å˜èªã¯ã™ã¹ã¦åŒã˜æ„å‘³ã‚’æŒã¤ã‚‚ã®ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
PIR, è³¼è²·æƒ…å ±ãƒã‚¹ã‚¿

# åˆ¶ç´„ 
ãƒ»ä»¥ä¸‹ã®Sources(æƒ…å ±æº)ã«è¨˜è¼‰ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚å¿…ãšæƒ…å ±æºã«è¨˜è¼‰ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸºã«å›ç­”ã‚’ä½œã£ã¦ãã ã•ã„
ãƒ»ååˆ†ãªæƒ…å ±ãŒãªã„å ´åˆã¯ã€ã‚ã‹ã‚‰ãªã„ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒ»ä»¥ä¸‹ã®Sources(æƒ…å ±æº)ã‚’ä½¿ç”¨ã—ãªã„å›ç­”ã¯ç”Ÿæˆã—ãªã„ã§ãã ã•ã„ ã€‚å›ç­”ã«ã¯å½¹å‰²(userã‚„assistantãªã©)ã®æƒ…å ±ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚
ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒä¸æ˜ç­ãªå ´åˆã¯ã€æ˜ç¢ºåŒ–ã®ãŸã‚ã«ãƒ¦ãƒ¼ã‚¶ã«å¿…ãšè³ªå•ã—ã¦ãã ã•ã„ã€‚
ãƒ»Sourcesã«ã¯ã€åå‰ã®å¾Œã«ã‚³ãƒ­ãƒ³ã¨å®Ÿéš›ã®æƒ…å ±ãŒç¶šãã¾ã™ã€‚å›ç­”ã§ä½¿ç”¨ã™ã‚‹å„äº‹å®Ÿã«ã¤ã„ã¦ã€å¸¸ã«Sourcesã®æƒ…å ±ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
  æƒ…å ±æºã‚’å‚ç…§ã™ã‚‹ã«ã¯ã€å„Contentæƒ…å ±ã®å‰æ®µã«ã‚ã‚‹filenameã®æƒ…å ±ã‚’åæ˜ ã—ã¦ãã ã•ã„ã€‚è§’ã‹ã£ã“ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
  Sourceså‚ç…§ãƒ«ãƒ¼ãƒ«ï¼š[filename] ã€€Sourceså‡ºåŠ›ä¾‹ï¼š[info1.txt]
ãƒ»Sourcesã‚’çµ„ã¿åˆã‚ã›ãªã„ã§ãã ã•ã„ã€‚å„Sourcesã‚’å€‹åˆ¥ã«ãƒªã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚ä¾‹ï¼š[info1.txt],[info1.txt]
ãƒ»æ—¥æœ¬èªã®è³ªå•ã®å ´åˆã¯ã€æ—¥æœ¬èªã§å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®è³ªå•ã®å ´åˆã¯ã€è‹±èªã§å›ç­”ã‚’ä½œæˆã—å›ç­”ã—ã¦ãã ã•ã„ã€‚    
"""

# Function to generate embeddings for title and content fields, also used for query embeddings
def generate_embeddings(text, text_limit=7000, compress_to_1024=False):
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r'[\n\r]+', ' ', text).strip()
    if len(text) > text_limit:
        logging.warning("Token limit exceeded maximum length, truncating...")
        text = text[:text_limit]

    response = client.embeddings.create(model=AZURE_OPENAI_EMBED_MODEL, input=text)
    embedding = response.data[0].embedding

    if compress_to_1024:
        if len(embedding) == 3072:
            embedding = np.array(embedding).reshape(3, 1024).mean(axis=0).tolist()
        else:
            raise ValueError(f"Cannot compress vector of length {len(embedding)} to 1024")

    return embedding

def query_vector_index(index_name, query, searchtype, top_k_parameter):
    vector = generate_embeddings(query, compress_to_1024=False)
    search_client = SearchClient(AI_SEARCH_ENDPOINT, index_name, AzureKeyCredential(AI_SEARCH_KEY))
    vector_query = VectorizedQuery(vector=vector, fields="contentVector")
    # searchtypeãŒvector_onlyã®å ´åˆã¯ã€search_textã‚’Noneã«ã™ã‚‹
    if searchtype == "Vector_only":
        search_text = None
    # searchtypeãŒvector_onlyä»¥å¤–ã®å ´åˆã¯ã€search_textã«queryã‚’è¨­å®šã™ã‚‹
    else:
        search_text = query

    # searchtypeãŒvector_onlyã‚‚ã—ãã¯Hybridã®å ´åˆ
    if searchtype == "Vector_only" or searchtype == "Hybrid":
        results = search_client.search(search_text=search_text, vector_queries=[vector_query], top=int(top_k_parameter))
    # searchtypeãŒFullã®å ´åˆ
    else:
        results = search_client.search(search_text=search_text, vector_queries=[vector_query], top=int(top_k_parameter),
                                       query_type='semantic', semantic_configuration_name=AI_SEACH_SEMANTIC)

    return results

# chatå±¥æ­´ã‚’ Cosmos DB ã«ä¿å­˜ã™ã‚‹
def add_to_cosmos(item):
    container.upsert_item(item)

def add_feedback_to_cosmos(item):
    container_feedback.upsert_item(item)

def randomname(n):
    randlst = [random.choice(string.ascii_letters + string.digits) for i in range(n)]
    return ''.join(randlst)

def query_image_index(query, top_k=3):
    vector = generate_embeddings(query, compress_to_1024=True)  # â† åœ§ç¸®ONï¼

    image_search_endpoint = os.getenv("AI_SEARCH_IMAGE_ENDPOINT")
    image_search_key = os.getenv("AI_SEARCH_IMAGE_KEY")
    image_index_name = os.getenv("AI_SEARCH_IMAGE_INDEX_NAME")

    if not all([image_search_endpoint, image_search_key, image_index_name]):
        raise ValueError("ç”»åƒç”¨AI Searchã®ç’°å¢ƒå¤‰æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    search_client = SearchClient(
        endpoint=image_search_endpoint,
        index_name=image_index_name,
        credential=AzureKeyCredential(image_search_key)
    )

    vector_query = VectorizedQuery(vector=vector, fields="content_embedding")  # â† ç”»åƒç”¨ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    try:
        results = search_client.search(
            search_text=None,
            vector_queries=[vector_query],
            top=top_k
        )
        return [r["content_path"] for r in results]
    except HttpResponseError as e:
        print("HTTP Response Error!")
        print(f"Status Code: {e.status_code}")
        print(f"Message: {e.message}")
        print(f"Details: {e.response.text}")
        raise
    

def get_image_from_image_blob(image_path: str) -> str:
    """
    BLOBã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä¸Šã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã€ãã®ãƒ‘ã‚¹ã‚’è¿”ã™ã€‚
    image_pathã¯ã€ç›¸å¯¾ãƒ‘ã‚¹ï¼ˆã‚³ãƒ³ãƒ†ãƒŠå†…ï¼‰ã‹ã€å®Œå…¨ãªURLã©ã¡ã‚‰ã‚‚å¯¾å¿œã€‚
    """
    if not image_path:
        raise ValueError("image_path is empty. Check AI Search index content.")

    # ãƒ•ãƒ«URLã®å ´åˆ
    if image_path.startswith("http"):
        blob_client = BlobClient.from_blob_url(blob_url=image_path)
    else:
        # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆï¼šäº‹å‰ã«å–å¾—ã—ãŸ image_blob_container_client ã‚’ä½¿ã†
        blob_client = image_blob_container_client.get_blob_client(blob=image_path)

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¸ä¿å­˜
    suffix = os.path.splitext(image_path)[1] or ".jpg"
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        blob_stream = blob_client.download_blob()
        blob_stream.readinto(tmp)
        return tmp.name


def upload_file_to_blob_storage(uploaded_file):
    blob_client = blob_container_client.get_blob_client(uploaded_file.name)
    blob_client.upload_blob(uploaded_file.getbuffer(), overwrite=True)
    print(f"Uploaded {uploaded_file.name} to Blob Storage.")

def download_file_from_blob_storage(file_name):
    blob_client = blob_container_client.get_blob_client(file_name)
    download_file_path = os.path.join(tempfile.gettempdir(), file_name)
    with open(download_file_path, "wb") as download_file:
        download_data = blob_client.download_blob()
        download_data.readinto(download_file)
    print(f"Downloaded {file_name} from Blob Storage to {download_file_path}.")
    return download_file_path


#ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«åå–å¾—
def get_indexed_filenames(index_name):
    endpoint = os.getenv("AI_SEARCH_ENDPOINT")  # ä¾‹: https://xxx.search.windows.net
    api_key = os.getenv("AI_SEARCH_KEY")
    api_version = "2023-10-01-Preview"

    url = f"{endpoint}/indexes/{index_name}/docs/search?api-version={api_version}"

    headers = {
        "Content-Type": "application/json",
        "api-key": api_key
    }

    payload = {
        "search": "*",
        "select": "fileName",  # ã¾ãŸã¯ "metadata_storage_name"
        "top": 1000
    }

    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()

    docs = response.json().get("value", [])
    return [doc.get("fileName", "NoName") for doc in docs]

def display_filenames_in_sidebar(filenames):
    st.sidebar.markdown("### ğŸ“„ å›ç­”å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«")

    st.sidebar.markdown("""
        <style>
        .sidebar-scroll {
            max-height: 200px;
            overflow-y: auto;
            padding: 0.5rem;
            font-size: 0.85rem;
            background-color: var(--secondary-background-color);
            border: 1px solid var(--secondary-background-color);
            border-radius: 5px;
        }
        </style>
    """, unsafe_allow_html=True)

    html = "<div class='sidebar-scroll'>"
    for i, name in enumerate(filenames, 1):
        html += f"{i}. ğŸ“„ {name}<br>"
    html += "</div>"

    st.sidebar.markdown(html, unsafe_allow_html=True)

def main():
    if "feedback_status" not in st.session_state or not isinstance(st.session_state["feedback_status"], dict):
        st.session_state["feedback_status"] = {} 
    if "last_qid" not in st.session_state:
        st.session_state["last_qid"] = None
     # å›ºå®šå€¤ã‚’ç›´æ¥å¤‰æ•°ã«ä»£å…¥ï¼ˆUIã¯è¡¨ç¤ºã®ã¿ï¼‰
    indexname = os.getenv("AI_SEARCH_INDEX_NAME")
    search_type = "Semantic_Hybrid"
    top_k_parameter = str(top_k_temp)
    Temperature_temp = 0.0
    SystemRole = SystemPrompt

    # Set page title and icon
    st.set_page_config(page_title="Kuraray RAG ã‚¢ãƒ—ãƒª", page_icon="ğŸ’¬", layout="wide")

    # Display title
    st.markdown("# Kuraray G-SAPãƒãƒ‹ãƒ¥ã‚¢ãƒ« Q&Aã‚¢ãƒ—ãƒª")

    # Display explanation in sidebar
    st.sidebar.header("Kuraray G-SAPãƒãƒ‹ãƒ¥ã‚¢ãƒ« Q&Aã‚¢ãƒ—ãƒª")
    st.sidebar.markdown("OneNoteã«è¨˜è¼‰ã•ã‚ŒãŸãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’æ¤œç´¢ã§ãã¾ã™ã€‚")
    
    centered_html = """
        <style>
        .center-container {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 70vh;
            text-align: center;
        }
        .center-container p {
            font-size: 20px;
            margin-bottom: 20px;
        }
        .center-container a {
            font-size: 18px;
            color: #1f77b4;
            text-decoration: none;
            margin: 5px 0;
        }
        .center-container a:hover {
            text-decoration: underline;
        }
        </style>

        <div class="center-container">
            <p>è©³ç´°ã¯ä¸‹è¨˜ã®ãƒªãƒ³ã‚¯å…ˆã‹ã‚‰ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯å…ˆã®æƒ…å ±ã‚’å‚è€ƒã«å›ç­”ã—ã¦ã„ã¾ã™ã€‚</p>
            <a href="https://kurarayglobal.sharepoint.com/:x:/s/krspp3/Eez5lJ1HHgBBgxy1h1s3K2IBz5gxagHng3kBNjeuK8qmSw" target="_blank">â–¶ QAé›†ãƒªã‚¹ãƒˆ</a>
            <a href="https://kurarayglobal.sharepoint.com/sites/krspp3/Business%20manual/Wave3%20JAPAN/07_Cross/QA%E9%9B%86!!%E7%B7%A8%E9%9B%86%E4%B8%8D%E5%8F%AF!!?d=w68ebcaa560ec4df396b00af9eae23c6d" target="_blank">â–¶ QAé›†</a>
            <a href="https://kurarayglobal.sharepoint.com/:f:/s/krspp3/EkJspieiifVGvz60d9oIJlYBHzpPKwSe8HZz_RO3mIri7A" target="_blank">â–¶ æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«</a>
        </div>
        """

    # HTMLã‚’åŸ‹ã‚è¾¼ã‚€
    st.markdown(centered_html, unsafe_allow_html=True)
     # --- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¡¨ç¤ºï¼ˆã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾å¿œï¼‰ ---
    #try:
        #filenames = get_indexed_filenames(indexname)
        #display_filenames_in_sidebar(filenames)
    #except Exception as e:
        #st.sidebar.error("ãƒ•ã‚¡ã‚¤ãƒ«åã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        #st.sidebar.exception(e)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®åˆæœŸåŒ–
    if "session_id" not in st.session_state:
        st.session_state['session_id'] = randomname(10)

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state['messages'] = []

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã®åˆæœŸåŒ–
    if 'file_processed' not in st.session_state:
        st.session_state['file_processed'] = False
    
    for _ in range(5):  # æ•°å­—ã‚’å¤‰ãˆã‚‹ã“ã¨ã§ä¸‹ã’å…·åˆã‚’èª¿æ•´
        st.sidebar.write("")

    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸå ´åˆã€ãƒãƒ£ãƒƒãƒˆã¨st.text_input,promptallã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã€‚
    if st.sidebar.button("Clear Chat"):
        st.session_state['messages'] = []
        promptall = ""
        # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆã—ã¦ä¿å­˜
        st.session_state['session_id'] = randomname(10)
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state['file_processed'] = False
        # ã‚¢ãƒ—ãƒªã‚’å†å®Ÿè¡Œã—ã¦ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
        st.rerun()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get('messages', [])
    for message in messages:
        # roleãŒassistantã ã£ãŸã‚‰ã€assistantã®chat_messageã‚’ä½¿ã†
        if message['role'] == 'assistant':
            with st.chat_message('assistant'):
                st.markdown(message['content'])
        # roleãŒuserã ã£ãŸã‚‰ã€userã®chat_messageã‚’ä½¿ã†
        elif message['role'] == 'user':
            with st.chat_message('user'):
                st.markdown(message['content'])
        else:  # ä½•ã‚‚å‡ºåŠ›ã—ãªã„
            pass

    # Add system role to session state
    if SystemRole:
        # æ—¢ã«roleãŒsystemã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯ã€è¿½åŠ ã—ãªã„ã€‚ãªã„å ´åˆã¯è¿½åŠ ã™ã‚‹ã€‚
        if not any(message["role"] == "system" for message in st.session_state.messages):
            st.session_state.messages.append({"role": "system", "content": SystemRole})

    # Azure AI Search ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹
    credential = AzureKeyCredential(AI_SEARCH_KEY)
    index_client = SearchIndexClient(
        endpoint=AI_SEARCH_ENDPOINT,
        credential=credential,
        api_version=AI_SEARCH_API_VERSION,
    )

    # ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®å…¥åŠ›ã‚’å–å¾—ã™ã‚‹
    if user_input := st.chat_input("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        # æ¤œç´¢ã™ã‚‹ã€‚search_fieldsã¯contentã‚’å¯¾è±¡ã«æ¤œç´¢ã™ã‚‹
        results = query_vector_index(indexname, user_input, search_type, top_k_parameter)

        # å¤‰æ•°ã‚’åˆæœŸåŒ–ã™ã‚‹
        prompt_source = ""
        sourcetemp = []

        with st.chat_message("user"):
            st.markdown(user_input)

        # st.session_state.messagesã®å†…å®¹ã‚’å¹³æ–‡ã«ã—ã¦ã€conversion_historyã«ä»£å…¥ã™ã‚‹ã€‚RoleãŒSystemã®å ´åˆã¯ã€ä»£å…¥ã—ãªã„ã€‚
        # å„messageã®contentã‚’æ”¹è¡Œã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚roleã‚‚ã‚ã‹ã‚‹ã‚ˆã†ã«ä»£å…¥ã™ã‚‹
        conversion_history = ""
        for message in st.session_state.messages:
            if message['role'] == 'system':
                pass
            else:
                conversion_history += message['role'] + ": " + message['content'] + "\n\n"

        # resultsã‹ã‚‰å„resultã®çµæœã‚’å¤‰æ•°prompt_sourceã«ä»£å…¥ã™ã‚‹ã€‚filepathã¨contentã®æƒ…å ±ã‚’ä»£å…¥ã™ã‚‹ã€‚
        for result in results:
            Score = result['@search.score']
            filename = result['fileName'] + "-" + str(result['chunkNo'])
            chunkNo = result['chunkNo']
            content = result['content']
            title = result['title']
            Keywords = result['keywords']

            # å¤‰æ•°prompt_sourceã«å„å¤‰æ•°ã®å€¤ã‚’è¿½åŠ ã™ã‚‹
            prompt_source += f"## filename: {filename}\n\n  ### score: {Score}\n\n  ### content: \n\n {content}\n\n"

            # filename, title, contentã®å†…å®¹ã‚’markdownå½¢å¼ã§sourcetempé…åˆ—ã«æ ¼ç´ã™ã‚‹
            # sourcetempã¯resultã®å†…å®¹ãŒå¤‰ã‚ã‚‹åº¦ã«é…åˆ—ã‚’å¤‰æ›´ã™ã‚‹
            sourcetemp.append(f"## filename: {filename}\n\n  ### title: {title}\n\n  ### content: \n\n {content}\n\n")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹
        promptall = SystemRole + "\n\n# Sources(æƒ…å ±æº): \n\n" + prompt_source + "# ä»Šã¾ã§ã®ä¼šè©±å±¥æ­´ï¼š\n\n" + conversion_history + "# å›ç­”ã®ç”Ÿæˆ\n\nãã‚Œã§ã¯ã€åˆ¶ç´„ã‚’è¸ã¾ãˆã¦æœ€é«˜ã®å›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚ã‚ãªãŸãªã‚‰ã§ãã‚‹ï¼"
        st.session_state.messages.append({"role": "user", "content": user_input})

        # expanderã‚’ä½œæˆã™ã‚‹
        #with st.sidebar.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤º"):
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹
            #st.markdown(promptall)
        st.session_state["last_user_input"] = user_input
        
        st.session_state["last_prompt_source"] = prompt_source

        #Jsonå½¢å¼ã®messagestempå¤‰æ•°ã«roleã‚’userã¨ã—ã¦ã€promptallã‚’ä»£å…¥ã™ã‚‹
        messagestemp = []
        messagestemp.append({"role": "system", "content": promptall})
        messagestemp.append({"role": "user", "content": user_input})

        with st.chat_message("assistant"):
            output = client.chat.completions.create(
                model=AZURE_OPENAI_CHAT_MODEL,
                messages=messagestemp,
                temperature=Temperature_temp,
                max_tokens=AZURE_OPENAI_CHAT_MAX_TOKENS,
                stream=True,
            )
            response = st.write_stream(output)
        
        qid = randomname(16)
        st.session_state["last_qid"] = qid
        st.session_state["feedback_status"][qid] = False
        

        st.session_state["last_response"] = response
        st.session_state.messages.append({"role": "assistant", "content": response})
            #outputå†…ã«[]å½¢å¼ãŒã‚ã‚‹å ´åˆã¯ã€[]å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ã—ã€sourcetempå†…ã®filenameã¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’æ¢ç´¢ã™ã‚‹
            #ä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°ã€sourcetempå†…ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚æ—¢ã«1å›è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€2å›ç›®ä»¥é™ã¯è¡¨ç¤ºã—ãªã„
        with st.expander("å‚ç…§å…ƒ"):
            displayed_files = []  # æ—¢ã«è¡¨ç¤ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
            if "[" in response:
                filename = re.findall(r'\[(.*?)\]', response)
                for i in range(len(filename)):
                    for j in range(len(sourcetemp)):
                        if filename[i] in sourcetemp[j] and filename[i] not in displayed_files:  # ãƒ•ã‚¡ã‚¤ãƒ«åãŒæ—¢ã«è¡¨ç¤ºã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
                            with st.popover(filename[i]):
                                st.write(sourcetemp[j])
                            displayed_files.append(filename[i])  # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿½è·¡ãƒªã‚¹ãƒˆã«è¿½åŠ 
            else:
                pass
        related_images = query_image_index(user_input)

        if related_images:
            st.markdown("### ğŸ“· é–¢é€£ç”»åƒ:")
            cols = st.columns(len(related_images))

            for idx, image_path in enumerate(related_images):
                local_image_path = get_image_from_image_blob(image_path)
                cols[idx].image(local_image_path, caption=os.path.basename(image_path))
        else:
            st.markdown("é–¢é€£ã™ã‚‹ç”»åƒã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # idã«ã¯ãƒ©ãƒ³ãƒ€ãƒ å€¤ã‚’æŒ¿å…¥ã™ã‚‹
        id1 = randomname(20)
        id2 = randomname(20)
        id3 = randomname(20)
        id4 = randomname(20)
        

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ Cosmos DB ã«ä¿å­˜ã™ã‚‹ã€‚
        add_to_cosmos({"id": id1, "session": st.session_state['session_id'], "role": "user", "content": user_input})
        add_to_cosmos({"id": id2, "session": st.session_state['session_id'], "role": "assistant", "content": response})
        add_to_cosmos({"id": id3, "session": st.session_state['session_id'], "role": "context", "content": prompt_source}) 
        add_to_cosmos({"id": id4, "session": st.session_state['session_id'], "role": "eval", "question": user_input, "answer": response, "context": prompt_source, "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}) 
    
    qid = st.session_state.get("last_qid")
    feedback_status = st.session_state.get("feedback_status", {})
    if st.session_state.get("last_response") and not feedback_status.get(st.session_state["last_qid"]):
        st.markdown("#### ã“ã®å›ç­”ã¯å‚è€ƒã«ãªã‚Šã¾ã—ãŸã‹ï¼Ÿ")
        id5 = randomname(20)
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ‘ Good", key=f"good_{st.session_state['session_id']}"):
                add_feedback_to_cosmos({"id": id5, "session": st.session_state['session_id'], "role": "feedback", "feedback-type": "good",  "question":  st.session_state["last_user_input"], "answer": st.session_state["last_response"], "context": st.session_state["last_prompt_source"], "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")})
                st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")
                st.session_state["feedback_status"][qid] = True 
                st.rerun()

        with col2:
            if st.button("ğŸ‘ Bad", key=f"bad_{st.session_state['session_id']}"):
                add_feedback_to_cosmos({"id": id5, "session": st.session_state['session_id'], "role": "feedback", "feedback-type": "bad", "question":  st.session_state["last_user_input"], "answer": st.session_state["last_response"], "context": st.session_state["last_prompt_source"],  "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")} )                                     
                st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")
                st.session_state["feedback_status"][qid] = True
                st.rerun()
                
        
if __name__ == '__main__':
    main()
